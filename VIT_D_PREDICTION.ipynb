{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxedcMrfk71EmkdrCE4jqf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sad-bzvS8eFp"
      },
      "outputs": [],
      "source": [
        "#Drive Connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#Data Reading\n",
        "!pip install -q xlrd9*09\n",
        "import pandas as pd\n",
        "!pip install scikeras[tensorflow]\n",
        "global vitd\n",
        "vitd = pd.read_excel('/content/drive/My Drive/Colab Notebooks/vitd.xlsx')\n",
        "global vitddef\n",
        "vitddef = pd.read_excel('/content/drive/My Drive/Colab Notebooks/vitddef.xlsx')\n",
        "global vitdlevel\n",
        "vitdlevel = pd.read_excel('/content/drive/My Drive/Colab Notebooks/vitdlevel.xlsx')\n",
        "#Missing Data Imputation\n",
        "#ITERATIVE IMPUTER\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "global vitd_imputed\n",
        "vitd_imputed = vitd.copy(deep=True)\n",
        "ii_imp = IterativeImputer(\n",
        "    max_iter=10, random_state=1121218\n",
        ")\n",
        "vitd_imputed.loc[:, :] = ii_imp.fit_transform(vitd_imputed)\n",
        "\n",
        "global vitddef_imputed\n",
        "vitddef_imputed = vitddef.copy(deep=True)\n",
        "ii_imp = IterativeImputer(\n",
        "    max_iter=10, random_state=1121218\n",
        ")\n",
        "vitddef_imputed.loc[:, :] = ii_imp.fit_transform(vitddef_imputed)\n",
        "\n",
        "global vitdlevel_imputed\n",
        "vitdlevel_imputed = vitdlevel.copy(deep=True)\n",
        "ii_imp = IterativeImputer(\n",
        "    max_iter=10, random_state=1121218\n",
        ")\n",
        "vitdlevel_imputed.loc[:, :] = ii_imp.fit_transform(vitdlevel_imputed)\n",
        "# BALACING DATASET\n",
        "from imblearn.over_sampling import SMOTE\n",
        "smote=SMOTE(k_neighbors=2)\n",
        "x_vitd_train,y_vitd_train=smote.fit_resample (x_vitd_train,y_vitd_train)\n",
        "x_vitd_test, y_vitd_test= smote.fit_resample (x_vitd_test, y_vitd_test)\n",
        "\n",
        "\n",
        "#ETC Feature Selection\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# Building the model\n",
        "extra_tree_forest = ExtraTreesClassifier(n_estimators = 10,\n",
        "\t\t\t\t\t\t\t\t\t\tcriterion ='entropy', max_features = 3)\n",
        "# Training the model\n",
        "extra_tree_forest.fit(x_vitd_train, y_vitd_train)\n",
        "\n",
        "# Computing the importance of each feature\n",
        "feature_importance = extra_tree_forest.feature_importances_\n",
        "\n",
        "# Normalizing the individual importances\n",
        "feature_importance_normalized = np.std([tree.feature_importances_ for tree in\n",
        "\t\t\t\t\t\t\t\t\t\textra_tree_forest.estimators_],\n",
        "\t\t\t\t\t\t\t\t\t\taxis = 0)\n",
        "# Plotting a Bar Graph to compare the models\n",
        "\n",
        "plt.bar(x_vitd_train.columns, feature_importance_normalized, align='center', width=0.7)\n",
        "plt.xlabel('Feature Labels')\n",
        "plt.ylabel('Feature Importances')\n",
        "plt.title('Comparison of different feature importances for Model 1')\n",
        "plt.xticks(fontsize=7, rotation='vertical')\n",
        "plt.show()\n",
        "# Training the model\n",
        "extra_tree_forest.fit(x_vitddef_train, y_vitddef_train)\n",
        "\n",
        "# Computing the importance of each feature\n",
        "feature_importance = extra_tree_forest.feature_importances_\n",
        "\n",
        "# Normalizing the individual importances\n",
        "feature_importance_normalized = np.std([tree.feature_importances_ for tree in\n",
        "\t\t\t\t\t\t\t\t\t\textra_tree_forest.estimators_],\n",
        "\t\t\t\t\t\t\t\t\t\taxis = 0)\n",
        "# Plotting a Bar Graph to compare the models\n",
        "plt.bar(x_vitd_train.columns, feature_importance_normalized, align='center', width=0.7)\n",
        "plt.xlabel('Feature Labels')\n",
        "plt.ylabel('Feature Importances')\n",
        "plt.title('Comparison of different feature importances for Model 2')\n",
        "plt.xticks(fontsize=7,rotation='vertical')\n",
        "plt.show()\n",
        "\n",
        "#Multi-Task LASSO Feature Selection\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import MultiTaskLasso, Lasso\n",
        "model = MultiTaskLasso(alpha=0.5)\n",
        "rfe = RFE(model, n_features_to_select=25)\n",
        "rfe.fit(x_vitdlevel_train, y_vitdlevel_train)\n",
        "y_pred = rfe.predict(x_vitdlevel_test)\n",
        "selected_features_MultiTaskLasso = \\\n",
        "    rfe.get_support(indices=True)\n",
        "print(\"Selected features using MultiTaskLasso:\",\n",
        "      selected_features_MultiTaskLasso)\n",
        "\n",
        "#%80-20 Train-Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "global x_vitd, y_vitd, x_vitddef, y_vitddef, x_vitdlevel, y_vitdlevel\n",
        "\n",
        "x_vitd = vitd_imputed.drop(['VitD','VitDLev'], axis=1).copy()\n",
        "y_vitd = vitd_imputed[\"VitDLev\"].values.reshape(-1, 1)\n",
        "\n",
        "x_vitddef = vitddef_imputed.drop(['VitD','VitDDefc'], axis=1).copy()\n",
        "y_vitddef = vitddef_imputed[\"VitDDefc\"].values.reshape(-1, 1)\n",
        "\n",
        "x_vitdlevel = vitdlevel_imputed.drop(['VitDLevel'], axis=1).copy()\n",
        "y_vitdlevel = vitdlevel_imputed[\"VitDLevel\"].values.reshape(-1, 1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "global x_vitd_train, x_vitd_test, y_vitd_train, y_vitd_test\n",
        "global x_vitddef_train, x_vitddef_test, y_vitddef_train,  y_vitddef_test\n",
        "global x_vitdlevel_train, x_vitdlevel_test, y_vitdlevel_train, y_vitdlevel_test\n",
        "\n",
        "x_vitd_train, x_vitd_test, y_vitd_train, y_vitd_test= train_test_split(x_vitd,y_vitd,random_state=104, test_size=0.20,shuffle=True)\n",
        "x_vitddef_train, x_vitddef_test, y_vitddef_train,  y_vitddef_test= train_test_split(x_vitddef,y_vitddef,random_state=104, test_size=0.20,shuffle=True)\n",
        "x_vitdlevel_train, x_vitdlevel_test, y_vitdlevel_train, y_vitdlevel_test= train_test_split(x_vitdlevel,y_vitdlevel,random_state=104, test_size=0.20,shuffle=True)\n",
        "\n",
        "#CNN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os\n",
        "import tempfile\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scikeras.wrappers  import KerasClassifier\n",
        "from scikeras.wrappers import KerasRegressor\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# baseline model\n",
        "def create_baseline():\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(25, input_shape=(25,), activation='relu'))\n",
        "  model.add(Dense(125, input_shape=(25,), activation='relu'))\n",
        "  model.add(Dense(25, input_shape=(25,), activation='relu'))\n",
        "\tmodel.add(Dense(3, activation='sigmoid'))\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "# evaluate baseline model with standardized dataset\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(model=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "results = cross_val_score(pipeline, x_vitd, y_vitd, cv=kfold)\n",
        "history = model.fit(X, y, validation_split=0.33, epochs=100, batch_size=10, verbose=0)\n",
        "# PLOT accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model 1 Accuracy', weight='bold')\n",
        "plt.ylabel('accuracy', weight='bold')\n",
        "plt.xlabel('epoch', weight='bold')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# PLOTr loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model 1 Loss', weight='bold')\n",
        "plt.ylabel('loss', weight='bold')\n",
        "plt.xlabel('epoch', weight='bold')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#RNN\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define RNN parameters\n",
        "input_size = 25\n",
        "output_size = [64, 25, 3]\n",
        "embedding_dim = 20000\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Create the RNN model\n",
        "class CustomRNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomRNN, self).__init__()\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(embedding_dim, output_size[0])\n",
        "        self.rnn_layers = [tf.keras.layers.SimpleRNN(units, activation='sigmoid', recurrent_initializer='orthogonal', return_sequences=True) for units in output_size]\n",
        "        self.dense_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for layer in self.rnn_layers:\n",
        "            x = layer(x)\n",
        "        x = self.dense_layer(x)\n",
        "        return x\n",
        "\n",
        "# Create the RNN model instance\n",
        "model1 = CustomRNN()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generate some dummy data\n",
        "x_vitd_train = np.random.randint(0, embedding_dim, size=(batch_size, input_size))\n",
        "y_vitd_train = np.random.randint(0, 2, size=(batch_size, 1))\n",
        "\n",
        "# Train the model\n",
        "history = model1.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Plot the training loss convergence graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model 1 Accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.show()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model 1 Loss', weight='bold')\n",
        "plt.ylabel('loss', weight='bold')\n",
        "plt.xlabel('epoch', weight='bold')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#LSTM\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define LSTM parameters\n",
        "input_size = 25\n",
        "output_size = [64, 25, 3]\n",
        "embedding_dim = 20000\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Create the LSTM model\n",
        "class CustomLSTM(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomLSTM, self).__init__()\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(embedding_dim, output_size[0])\n",
        "        self.lstm_layers = [tf.keras.layers.LSTM(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=True) for units in output_size]\n",
        "        self.dense_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for layer in self.lstm_layers:\n",
        "            x = layer(x)\n",
        "        x = self.dense_layer(x)\n",
        "        return x\n",
        "\n",
        "# Create the LSTM model instance\n",
        "model1 = CustomLSTM()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generate some dummy data\n",
        "x_vitd_train = np.random.randint(0, embedding_dim, size=(batch_size, input_size))\n",
        "y_vitd_train = np.random.randint(0, 2, size=(batch_size, 1))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_vitd_train, y_vitd_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Plot the training accuracy convergence graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model 1 Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Generate some dummy test data\n",
        "x_vitd_test = np.random.randint(0, embedding_dim, size=(batch_size, input_size))\n",
        "y__vitd_test = np.random.randint(0, 2, size=(batch_size, 1))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "plt.plot(history.history['test_loss'])\n",
        "plt.title('Model 1 Loss', weight='bold')\n",
        "plt.ylabel('loss', weight='bold')\n",
        "plt.xlabel('epoch', weight='bold')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "#AUTOENCODER\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define autoencoder parameters\n",
        "input_size = 25\n",
        "encoder_layers = [50, 25, 3]\n",
        "decoder_layers = [3, 25, 50]\n",
        "output_size = 3\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Create the autoencoder model\n",
        "class Autoencoder(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder_layers = [tf.keras.layers.Dense(units, activation='relu') for units in encoder_layers]\n",
        "        self.decoder_layers = [tf.keras.layers.Dense(units, activation='relu') for units in decoder_layers]\n",
        "        self.output_layer = tf.keras.layers.Dense(output_size, activation='relu')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs\n",
        "        for layer in self.encoder_layers:\n",
        "            x = layer(x)\n",
        "        for layer in self.decoder_layers:\n",
        "            x = layer(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "# Create the autoencoder model instance\n",
        "model1 = Autoencoder()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='rmsprop', loss='mse')\n",
        "\n",
        "# Generate some dummy data\n",
        "x_vitd_train = np.random.rand(batch_size, input_size)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_vitd_train, x_vitd_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Plot the training loss convergence graph\n",
        "plt.plot(history.history['loss'])\n",
        "plt.title('Model 1 Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()\n",
        "\n",
        "# Generate some dummy test data\n",
        "x_vitd_test = np.random.rand(batch_size, input_size)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss = model.evaluate(x_test, x_test)\n",
        "\n",
        "print(f'Test Loss: {test_loss}')\n",
        "\n",
        "#GRU\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define GRU parameters\n",
        "input_size = 25\n",
        "output_size = [64, 25, 3]\n",
        "embedding_dim = 20000\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "\n",
        "# Create the GRU model\n",
        "class CustomGRU(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CustomGRU, self).__init__()\n",
        "        self.embedding_layer = tf.keras.layers.Embedding(embedding_dim, output_size[0])\n",
        "        self.gru_layers = [tf.keras.layers.GRU(units, activation='tanh', recurrent_activation='sigmoid', return_sequences=True) for units in output_size]\n",
        "        self.dense_layer = tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.embedding_layer(inputs)\n",
        "        for layer in self.gru_layers:\n",
        "            x = layer(x)\n",
        "        x = self.dense_layer(x)\n",
        "        return x\n",
        "\n",
        "# Create the GRU model instance\n",
        "model1 = CustomGRU()\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Generate some dummy data\n",
        "x_vitd_train = np.random.randint(0, embedding_dim, size=(batch_size, input_size))\n",
        "y_vitd_train = np.random.randint(0, 2, size=(batch_size, 1))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_vitd_train, y_vitd_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "\n",
        "# Plot the training accuracy convergence graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.title('Model 1 Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Generate some dummy test data\n",
        "x_vitd_test = np.random.randint(0, embedding_dim, size=(batch_size, input_size))\n",
        "y_vitd_test = np.random.randint(0, 2, size=(batch_size, 1))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_vitd_test, y_vitd_test)\n",
        "\n",
        "print(f'Test Loss: {test_loss}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n"
      ]
    }
  ]
}